{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243c2a77",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data\n",
    "\n",
    "Load the dataset and show:\n",
    "- Size and structure\n",
    "- Data descriptions\n",
    "- Boxplot distributions\n",
    "- Correlation between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"ml_python_labexam_2023_02_03.csv\")\n",
    "\n",
    "# Show size\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60425ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data descriptions\n",
    "print(\"Statistical summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTotal missing values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4e1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for all numeric columns\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "df.boxplot(ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplot of All Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Display correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show correlation with target variable 'y'\n",
    "print(\"Correlation with target variable (y):\")\n",
    "target_correlation = correlation_matrix['y'].sort_values(ascending=False)\n",
    "print(target_correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c561636",
   "metadata": {},
   "source": [
    "## 2. Comment on Exploration and Identify Low Correlation Features\n",
    "\n",
    "Identify features with absolute correlation < 0.15 with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find features with absolute correlation < 0.15 with target\n",
    "threshold = 0.15\n",
    "low_corr_features = target_correlation[abs(target_correlation) < threshold].index.tolist()\n",
    "\n",
    "# Remove 'y' from the list if present\n",
    "if 'y' in low_corr_features:\n",
    "    low_corr_features.remove('y')\n",
    "\n",
    "print(f\"Features with absolute correlation < {threshold} with target 'y':\")\n",
    "print(low_corr_features)\n",
    "print(f\"\\nNumber of low correlation features: {len(low_corr_features)}\")\n",
    "\n",
    "# Show their correlation values\n",
    "print(\"\\nCorrelation values for these features:\")\n",
    "for feature in low_corr_features:\n",
    "    print(f\"{feature}: {target_correlation[feature]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d285d3",
   "metadata": {},
   "source": [
    "### Comments on Exploration:\n",
    "\n",
    "**Dataset Structure:**\n",
    "- The dataset contains regression data with multiple numeric features and a target variable 'y'\n",
    "- All features appear to be continuous numeric values\n",
    "\n",
    "**Missing Values:**\n",
    "- The dataset shows presence/absence of missing values\n",
    "\n",
    "**Feature Distributions:**\n",
    "- Boxplots reveal the distribution and potential outliers in each feature\n",
    "- Features may have different scales and ranges\n",
    "\n",
    "**Correlation Analysis:**\n",
    "- Some features show strong correlation with the target variable\n",
    "- Features with absolute correlation < 0.15 are considered weakly correlated\n",
    "- These weak features may not contribute significantly to prediction\n",
    "- Removing them could simplify the model without losing much predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68404d",
   "metadata": {},
   "source": [
    "## 3. Train/Test Linear Regression (Full Dataset)\n",
    "\n",
    "Train and test a multivariate linear regressor on all features and show RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a799db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X_full = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(\n",
    "    X_full, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Full dataset split:\")\n",
    "print(f\"Training set size: {X_train_full.shape}\")\n",
    "print(f\"Test set size: {X_test_full.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression on full dataset\n",
    "lr_full = LinearRegression()\n",
    "lr_full.fit(X_train_full, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_full = lr_full.predict(X_test_full)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_full = np.sqrt(mean_squared_error(y_test, y_pred_full))\n",
    "\n",
    "print(\"Linear Regression on Full Dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_full:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94990b9e",
   "metadata": {},
   "source": [
    "## 4. Train/Test Linear Regression (Reduced Dataset)\n",
    "\n",
    "Train and test on reduced dataset (dropping features with correlation < 0.15) and show RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43260b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reduced dataset by dropping low correlation features\n",
    "X_reduced = df.drop(columns=['y'] + low_corr_features)\n",
    "\n",
    "print(f\"Reduced dataset features: {X_reduced.columns.tolist()}\")\n",
    "print(f\"Number of features: {X_reduced.shape[1]}\")\n",
    "print(f\"Features dropped: {low_corr_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867afef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split reduced dataset\n",
    "X_train_reduced, X_test_reduced, y_train_r, y_test_r = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Reduced dataset split:\")\n",
    "print(f\"Training set size: {X_train_reduced.shape}\")\n",
    "print(f\"Test set size: {X_test_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c022e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression on reduced dataset\n",
    "lr_reduced = LinearRegression()\n",
    "lr_reduced.fit(X_train_reduced, y_train_r)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_reduced = lr_reduced.predict(X_test_reduced)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_reduced = np.sqrt(mean_squared_error(y_test_r, y_pred_reduced))\n",
    "\n",
    "print(\"Linear Regression on Reduced Dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_reduced:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597b953",
   "metadata": {},
   "source": [
    "## 5. Train/Test Decision Tree Regressor (Reduced Dataset)\n",
    "\n",
    "Train and test Decision Tree Regressor on reduced dataset and show RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree Regressor on reduced dataset\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "dt_regressor.fit(X_train_reduced, y_train_r)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_regressor.predict(X_test_reduced)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_dt = np.sqrt(mean_squared_error(y_test_r, y_pred_dt))\n",
    "\n",
    "print(\"Decision Tree Regressor on Reduced Dataset:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb26c39a",
   "metadata": {},
   "source": [
    "## 6. Optimize Decision Tree Depth with Cross Validation\n",
    "\n",
    "Search for optimal max_depth that minimizes RMSE using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4577f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for max_depth\n",
    "param_grid = {\n",
    "    'max_depth': list(range(1, 21)) + [None]\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "# Note: GridSearchCV maximizes the score, but we want to minimize RMSE\n",
    "# So we use negative MSE as scoring metric\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "print(\"Optimizing Decision Tree depth with Cross Validation...\")\n",
    "grid_search.fit(X_train_reduced, y_train_r)\n",
    "\n",
    "# Get best model\n",
    "best_dt = grid_search.best_estimator_\n",
    "best_depth = grid_search.best_params_['max_depth']\n",
    "\n",
    "print(f\"\\nBest max_depth: {best_depth}\")\n",
    "print(f\"Best cross-validation MSE: {-grid_search.best_score_:.4f}\")\n",
    "print(f\"Best cross-validation RMSE: {np.sqrt(-grid_search.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the optimized model on test set\n",
    "y_pred_best_dt = best_dt.predict(X_test_reduced)\n",
    "rmse_best_dt = np.sqrt(mean_squared_error(y_test_r, y_pred_best_dt))\n",
    "\n",
    "print(\"Optimized Decision Tree Regressor on Test Set:\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_best_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ec493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RMSE vs max_depth\n",
    "cv_results = grid_search.cv_results_\n",
    "depths = [p['max_depth'] for p in cv_results['params']]\n",
    "mean_scores = np.sqrt(-cv_results['mean_test_score'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(depths)), mean_scores, marker='o')\n",
    "plt.xticks(range(len(depths)), [str(d) for d in depths], rotation=45)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Cross-Validation RMSE')\n",
    "plt.title('Decision Tree: RMSE vs max_depth')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=depths.index(best_depth), color='r', linestyle='--', label=f'Best depth: {best_depth}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4f3be",
   "metadata": {},
   "source": [
    "## 7. Comment on Results\n",
    "\n",
    "Compare all models and discuss findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9be4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Linear Regression (Full)',\n",
    "        'Linear Regression (Reduced)',\n",
    "        'Decision Tree (Reduced)',\n",
    "        'Decision Tree Optimized (Reduced)'\n",
    "    ],\n",
    "    'RMSE': [rmse_full, rmse_reduced, rmse_dt, rmse_best_dt],\n",
    "    'Features': [\n",
    "        X_full.shape[1],\n",
    "        X_reduced.shape[1],\n",
    "        X_reduced.shape[1],\n",
    "        X_reduced.shape[1]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: RMSE comparison\n",
    "axes[0].bar(range(len(results)), results['RMSE'], \n",
    "            color=['skyblue', 'lightblue', 'lightcoral', 'coral'])\n",
    "axes[0].set_xticks(range(len(results)))\n",
    "axes[0].set_xticklabels(results['Model'], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('Model Performance Comparison')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(results['RMSE']):\n",
    "    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Feature count\n",
    "axes[1].bar(range(len(results)), results['Features'],\n",
    "            color=['skyblue', 'lightblue', 'lightcoral', 'coral'])\n",
    "axes[1].set_xticks(range(len(results)))\n",
    "axes[1].set_xticklabels(results['Model'], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Number of Features')\n",
    "axes[1].set_title('Number of Features Used')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(results['Features']):\n",
    "    axes[1].text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933a0fd",
   "metadata": {},
   "source": [
    "### Final Comments on Results:\n",
    "\n",
    "**1. Effect of Feature Reduction:**\n",
    "- Linear Regression (Full) uses all features\n",
    "- Linear Regression (Reduced) drops features with correlation < 0.15\n",
    "- Comparing RMSE values shows whether removing weakly correlated features affects performance\n",
    "- If RMSE remains similar or improves, feature reduction is beneficial (simpler model, less overfitting)\n",
    "\n",
    "**2. Linear Regression vs Decision Tree:**\n",
    "- Linear Regression assumes linear relationships between features and target\n",
    "- Decision Tree can capture non-linear relationships\n",
    "- Comparing their RMSE shows which assumption fits the data better\n",
    "\n",
    "**3. Optimization Impact:**\n",
    "- The unoptimized Decision Tree may overfit (if max_depth is too large)\n",
    "- Cross-validation finds the optimal depth to balance bias and variance\n",
    "- The optimized model should show better generalization (lower RMSE on test set)\n",
    "\n",
    "**4. Best Model Selection:**\n",
    "- The model with the lowest RMSE on the test set is the best performer\n",
    "- Consider also model complexity: simpler models are preferred if performance is similar\n",
    "- The optimized Decision Tree typically provides the best balance\n",
    "\n",
    "**5. Practical Insights:**\n",
    "- Feature selection can improve model interpretability and reduce computational cost\n",
    "- Hyperparameter tuning is essential for tree-based models\n",
    "- Cross-validation provides robust performance estimates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
