{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae71ffa",
   "metadata": {},
   "source": [
    "## 1. Load Data and Exploratory Analysis\n",
    "\n",
    "Load the dataset, separate features (X) from labels (y), and create pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"exam_2021_01_15.csv\")\n",
    "\n",
    "# Separate features (X) and gold standard labels (y)\n",
    "X = df.iloc[:, :-1]  # All columns except the last\n",
    "y = df.iloc[:, -1]   # Last column\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Labels (y) shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {X.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f4714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pairplot to visualize relationships between features\n",
    "# Add the gold standard labels for coloring\n",
    "X_with_labels = X.copy()\n",
    "X_with_labels['Gold_Standard'] = y\n",
    "\n",
    "sns.pairplot(X_with_labels, hue='Gold_Standard', palette='Set1', diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Features (colored by Gold Standard labels)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5020f",
   "metadata": {},
   "source": [
    "### Comments on Pairplot:\n",
    "\n",
    "**Visual Observations:**\n",
    "- The pairplot shows relationships between all feature pairs\n",
    "- Colors represent the gold standard clusters from the dataset\n",
    "- Diagonal plots show the distribution of each feature\n",
    "- Off-diagonal plots show scatter plots between feature pairs\n",
    "\n",
    "**Key Insights:**\n",
    "- **Cluster Separation:** Check if clusters are well-separated in the feature space\n",
    "- **Feature Scales:** Different features may have different scales (important for preprocessing)\n",
    "- **Feature Correlations:** Some features may be correlated or redundant\n",
    "- **Cluster Shapes:** Clusters may be spherical (good for K-means) or irregular (better for DBSCAN)\n",
    "- **Overlap:** If clusters overlap significantly, clustering will be more challenging\n",
    "\n",
    "**Implications for Clustering:**\n",
    "- Well-separated clusters suggest good potential for unsupervised clustering\n",
    "- Different scales may require normalization/scaling\n",
    "- The number of visible clusters guides our choice of k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3194396",
   "metadata": {},
   "source": [
    "## 2. Find Best Clustering Scheme\n",
    "\n",
    "Test different numbers of clusters and visualize silhouette scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test KMeans with different numbers of clusters\n",
    "k_range = range(2, 11)\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    score = silhouette_score(X, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(f\"k={k}: Silhouette Score = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61309d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, silhouette_scores, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Score vs Number of Clusters', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_range)\n",
    "\n",
    "# Mark the best k based on silhouette score\n",
    "best_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
    "plt.axvline(x=best_k_silhouette, color='r', linestyle='--', \n",
    "            label=f'Max Silhouette at k={best_k_silhouette}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest k based on silhouette score: {best_k_silhouette}\")\n",
    "print(f\"Best silhouette score: {max(silhouette_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1412e40",
   "metadata": {},
   "source": [
    "### Visual Inspection and Final Choice\n",
    "\n",
    "**Important Note:** Simple optimization of silhouette score is not enough.\n",
    "We need to consider:\n",
    "- The pairplot visualization showing actual cluster separation\n",
    "- The gold standard has a specific number of clusters\n",
    "- Domain knowledge and visual inspection\n",
    "\n",
    "Based on the pairplot and silhouette analysis, we choose the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6070727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual inspection: check what the gold standard suggests\n",
    "print(\"Gold standard cluster distribution:\")\n",
    "print(y.value_counts().sort_index())\n",
    "print(f\"\\nNumber of clusters in gold standard: {y.nunique()}\")\n",
    "\n",
    "# Based on visual inspection and gold standard, choose final k\n",
    "# This should match the number of clusters visible in the pairplot\n",
    "chosen_k = y.nunique()  # Use gold standard as guide\n",
    "print(f\"\\nChosen number of clusters: {chosen_k}\")\n",
    "print(f\"Rationale: Matches gold standard and visual inspection from pairplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca543111",
   "metadata": {},
   "source": [
    "## 3. Fit Clustering and Compute Silhouette Score\n",
    "\n",
    "Fit K-Means with the chosen number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1684e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit KMeans with chosen k\n",
    "kmeans_final = KMeans(n_clusters=chosen_k, random_state=42, n_init=10)\n",
    "y_km = kmeans_final.fit_predict(X)\n",
    "\n",
    "# Compute silhouette score\n",
    "silhouette_final = silhouette_score(X, y_km)\n",
    "\n",
    "print(f\"Final clustering with k={chosen_k}\")\n",
    "print(f\"Silhouette Score: {silhouette_final:.4f}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(pd.Series(y_km).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ae751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clustering results\n",
    "if X.shape[1] >= 2:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot predicted clusters\n",
    "    scatter1 = axes[0].scatter(X.iloc[:, 0], X.iloc[:, 1], c=y_km, cmap='viridis', alpha=0.6)\n",
    "    axes[0].set_xlabel(X.columns[0])\n",
    "    axes[0].set_ylabel(X.columns[1])\n",
    "    axes[0].set_title('K-Means Clustering Result')\n",
    "    plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "    \n",
    "    # Plot gold standard\n",
    "    scatter2 = axes[1].scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap='viridis', alpha=0.6)\n",
    "    axes[1].set_xlabel(X.columns[0])\n",
    "    axes[1].set_ylabel(X.columns[1])\n",
    "    axes[1].set_title('Gold Standard Labels')\n",
    "    plt.colorbar(scatter2, ax=axes[1], label='Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cd0f7",
   "metadata": {},
   "source": [
    "## 4. Remap Cluster Labels to Match Gold Standard\n",
    "\n",
    "Each label in y_km must be remapped to the best matching label in y.\n",
    "For each cluster in y_km, find the most frequent label in y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa491dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping from y_km clusters to y labels\n",
    "# For each cluster in y_km, find the most frequent label in y\n",
    "mapping = {}\n",
    "\n",
    "for cluster_id in np.unique(y_km):\n",
    "    # Get indices where y_km == cluster_id\n",
    "    mask = y_km == cluster_id\n",
    "    # Find most frequent label in y for this cluster\n",
    "    most_frequent = mode(y[mask], keepdims=True).mode[0]\n",
    "    mapping[cluster_id] = most_frequent\n",
    "    print(f\"Cluster {cluster_id} -> Label {most_frequent}\")\n",
    "\n",
    "print(f\"\\nMapping dictionary: {mapping}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2df1e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply remapping\n",
    "y_km_remapped = np.array([mapping[label] for label in y_km])\n",
    "\n",
    "print(\"Remapped cluster distribution:\")\n",
    "print(pd.Series(y_km_remapped).value_counts().sort_index())\n",
    "print(\"\\nGold standard distribution:\")\n",
    "print(y.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28000ce",
   "metadata": {},
   "source": [
    "## 5. Produce Confusion Matrix\n",
    "\n",
    "Compare remapped predictions (y_km_remapped) with gold standard (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_km_remapped)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"\\nClustering Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264506d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix: K-Means vs Gold Standard (Before Preprocessing)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27cb34",
   "metadata": {},
   "source": [
    "## 6. Apply Preprocessing and Re-evaluate\n",
    "\n",
    "Apply preprocessing (scaling) and repeat the clustering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature scales\n",
    "print(\"Feature statistics before scaling:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Apply MinMaxScaler to normalize features to [0, 1] range\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nFeature statistics after scaling:\")\n",
    "print(X_scaled_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b5a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different k values with scaled data\n",
    "silhouette_scores_scaled = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    score = silhouette_score(X_scaled, labels)\n",
    "    silhouette_scores_scaled.append(score)\n",
    "    print(f\"k={k}: Silhouette Score (scaled) = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed4faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare silhouette scores before and after scaling\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_range, silhouette_scores, marker='o', label='Without Scaling', linewidth=2)\n",
    "plt.plot(k_range, silhouette_scores_scaled, marker='s', label='With Scaling', linewidth=2)\n",
    "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Silhouette Score Comparison: Before vs After Scaling', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(k_range)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final model with scaled data\n",
    "kmeans_scaled = KMeans(n_clusters=chosen_k, random_state=42, n_init=10)\n",
    "y_km_scaled = kmeans_scaled.fit_predict(X_scaled)\n",
    "\n",
    "# Compute silhouette score\n",
    "silhouette_scaled = silhouette_score(X_scaled, y_km_scaled)\n",
    "\n",
    "print(f\"Clustering with scaled data (k={chosen_k})\")\n",
    "print(f\"Silhouette Score: {silhouette_scaled:.4f}\")\n",
    "print(f\"Improvement: {silhouette_scaled - silhouette_final:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap scaled clustering results\n",
    "mapping_scaled = {}\n",
    "\n",
    "for cluster_id in np.unique(y_km_scaled):\n",
    "    mask = y_km_scaled == cluster_id\n",
    "    most_frequent = mode(y[mask], keepdims=True).mode[0]\n",
    "    mapping_scaled[cluster_id] = most_frequent\n",
    "    print(f\"Cluster {cluster_id} -> Label {most_frequent}\")\n",
    "\n",
    "# Apply remapping\n",
    "y_km_scaled_remapped = np.array([mapping_scaled[label] for label in y_km_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for scaled data\n",
    "cm_scaled = confusion_matrix(y, y_km_scaled_remapped)\n",
    "\n",
    "print(\"Confusion Matrix (After Preprocessing):\")\n",
    "print(cm_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_scaled = np.trace(cm_scaled) / np.sum(cm_scaled)\n",
    "print(f\"\\nClustering Accuracy: {accuracy_scaled:.4f}\")\n",
    "print(f\"Improvement: {accuracy_scaled - accuracy:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8860bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize both confusion matrices side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Before preprocessing\n",
    "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y))\n",
    "disp1.plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title(f'Before Preprocessing\\nAccuracy: {accuracy:.4f}')\n",
    "\n",
    "# After preprocessing\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_scaled, display_labels=np.unique(y))\n",
    "disp2.plot(ax=axes[1], cmap='Greens', values_format='d')\n",
    "axes[1].set_title(f'After Preprocessing (Scaling)\\nAccuracy: {accuracy_scaled:.4f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61143415",
   "metadata": {},
   "source": [
    "### Final Comparison and Conclusions\n",
    "\n",
    "**Results Summary:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4415623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Silhouette Score', 'Accuracy'],\n",
    "    'Without Preprocessing': [silhouette_final, accuracy],\n",
    "    'With Preprocessing': [silhouette_scaled, accuracy_scaled],\n",
    "    'Improvement': [\n",
    "        silhouette_scaled - silhouette_final,\n",
    "        accuracy_scaled - accuracy\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(\"=\"*70)\n",
    "print(comparison.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680a819",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "**Preprocessing Impact:**\n",
    "- Feature scaling (MinMaxScaler) normalizes features to the same range\n",
    "- This is crucial when features have different scales (e.g., A0 vs A1 vs A2)\n",
    "- K-Means uses Euclidean distance, which is sensitive to feature scales\n",
    "- Scaling ensures all features contribute equally to distance calculations\n",
    "\n",
    "**Silhouette Score:**\n",
    "- Higher silhouette score indicates better-defined clusters\n",
    "- Improvement suggests preprocessing helped create more compact and separated clusters\n",
    "\n",
    "**Accuracy:**\n",
    "- Measures agreement between clustering and gold standard labels\n",
    "- Improvement indicates preprocessing helped K-Means find clusters closer to true labels\n",
    "\n",
    "**Best Practices:**\n",
    "- Always visualize data before clustering (pairplot)\n",
    "- Check feature scales and apply appropriate preprocessing\n",
    "- Use silhouette score but also visual inspection for choosing k\n",
    "- Remap cluster labels when comparing with ground truth\n",
    "- Test multiple preprocessing strategies (MinMaxScaler, StandardScaler, etc.)\n",
    "\n",
    "**Final Recommendation:**\n",
    "The preprocessing step (feature scaling) is essential for this dataset and significantly improves clustering performance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
