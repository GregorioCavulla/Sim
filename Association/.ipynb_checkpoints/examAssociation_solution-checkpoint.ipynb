{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60765ebc",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load the Excel file and show size and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3e4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e307ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "df = pd.read_excel(\"Online-Retail-France.xlsx\")\n",
    "\n",
    "# Show size\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "\n",
    "# Show a portion of the content\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acccc0a",
   "metadata": {},
   "source": [
    "## 2. Count Unique Descriptions\n",
    "\n",
    "Print the number of unique Description values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique descriptions\n",
    "unique_descriptions = df[\"Description\"].nunique()\n",
    "print(f\"Number of unique Description values: {unique_descriptions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da8a2a",
   "metadata": {},
   "source": [
    "## 3. Clean Descriptions\n",
    "\n",
    "Remove leading/trailing spaces from descriptions using str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean descriptions by removing leading/trailing spaces\n",
    "df[\"Description\"] = df[\"Description\"].str.strip()\n",
    "\n",
    "# Count unique descriptions after cleaning\n",
    "unique_descriptions_cleaned = df[\"Description\"].nunique()\n",
    "print(f\"Number of unique Description values after str.strip(): {unique_descriptions_cleaned}\")\n",
    "print(f\"Number of descriptions unified: {unique_descriptions - unique_descriptions_cleaned}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66b648f",
   "metadata": {},
   "source": [
    "## 4. Remove Rows Without InvoiceNo\n",
    "\n",
    "Check for and remove rows without InvoiceNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing InvoiceNo\n",
    "print(f\"Rows before removing missing InvoiceNo: {df.shape[0]}\")\n",
    "print(f\"Rows with missing InvoiceNo: {df['InvoiceNo'].isnull().sum()}\")\n",
    "\n",
    "# Remove rows without InvoiceNo\n",
    "df = df.dropna(subset=[\"InvoiceNo\"])\n",
    "\n",
    "print(f\"Rows after removing missing InvoiceNo: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e623ea9",
   "metadata": {},
   "source": [
    "## 5. Remove Credit Transactions\n",
    "\n",
    "Remove InvoiceNo starting with 'C' (credit transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for InvoiceNo starting with 'C'\n",
    "print(f\"Rows before removing credit transactions: {df.shape[0]}\")\n",
    "credit_transactions = df[\"InvoiceNo\"].astype(str).str.contains(\"C\").sum()\n",
    "print(f\"Rows with InvoiceNo starting with 'C': {credit_transactions}\")\n",
    "\n",
    "# Remove rows where InvoiceNo starts with 'C'\n",
    "df = df[~df[\"InvoiceNo\"].astype(str).str.contains(\"C\")]\n",
    "\n",
    "print(f\"Rows after removing credit transactions: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ff323",
   "metadata": {},
   "source": [
    "## 6. Remove POSTAGE Items\n",
    "\n",
    "Remove rows with POSTAGE in Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for POSTAGE items\n",
    "print(f\"Rows before removing POSTAGE: {df.shape[0]}\")\n",
    "postage_rows = df[\"Description\"].str.contains(\"POSTAGE\", na=False).sum()\n",
    "print(f\"Rows with POSTAGE: {postage_rows}\")\n",
    "\n",
    "# Remove rows with POSTAGE\n",
    "df = df[~df[\"Description\"].str.contains(\"POSTAGE\", na=False)]\n",
    "\n",
    "print(f\"Rows after removing POSTAGE: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448853c6",
   "metadata": {},
   "source": [
    "## 7. Create Basket Matrix\n",
    "\n",
    "Group by InvoiceNo and Description, sum Quantity, unstack to create one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basket matrix\n",
    "# Group by InvoiceNo and Description, sum Quantity\n",
    "basket = (\n",
    "    df.groupby([\"InvoiceNo\", \"Description\"])[\"Quantity\"]\n",
    "    .sum()\n",
    "    .unstack()\n",
    "    .reset_index()\n",
    "    .fillna(0)\n",
    "    .set_index(\"InvoiceNo\")\n",
    ")\n",
    "\n",
    "print(\"Basket matrix shape:\", basket.shape)\n",
    "print(f\"Number of transactions: {basket.shape[0]}\")\n",
    "print(f\"Number of unique items: {basket.shape[1]}\")\n",
    "print(\"\\nFirst few rows and columns of basket matrix:\")\n",
    "basket.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f0eff8",
   "metadata": {},
   "source": [
    "## 8. Convert to Boolean\n",
    "\n",
    "Convert positive values to True and non-positive values to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define encoding function\n",
    "def encode(x):\n",
    "    return x > 0\n",
    "\n",
    "# Apply encoding to basket\n",
    "basket_bool = basket.map(encode)\n",
    "\n",
    "print(\"Boolean basket matrix shape:\", basket_bool.shape)\n",
    "print(\"\\nFirst few rows and columns of boolean basket:\")\n",
    "print(basket_bool.iloc[:5, :5])\n",
    "\n",
    "# Verify correctness\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"All values are boolean: {basket_bool.dtypes.apply(lambda x: x == bool).all()}\")\n",
    "print(f\"Sample values from original basket (first 3 items):\")\n",
    "print(basket.iloc[0, :3])\n",
    "print(f\"Corresponding boolean values:\")\n",
    "print(basket_bool.iloc[0, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c40f4f",
   "metadata": {},
   "source": [
    "## 9. Find Optimal min_support\n",
    "\n",
    "Find the maximum min_support value that generates at least 20 rules with lift >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal min_support using a loop\n",
    "min_support = 1.0\n",
    "rules = pd.DataFrame()\n",
    "\n",
    "print(\"Searching for optimal min_support...\\n\")\n",
    "\n",
    "while min_support > 0:\n",
    "    # Generate frequent itemsets\n",
    "    frequent_itemsets = apriori(\n",
    "        basket_bool,\n",
    "        min_support=min_support,\n",
    "        use_colnames=True\n",
    "    )\n",
    "    \n",
    "    # Generate association rules\n",
    "    if len(frequent_itemsets) > 0:\n",
    "        rules = association_rules(\n",
    "            frequent_itemsets,\n",
    "            metric=\"lift\",\n",
    "            min_threshold=1\n",
    "        )\n",
    "    \n",
    "    print(f\"min_support={min_support:.2f}: {len(rules)} rules found\")\n",
    "    \n",
    "    # Check if we have at least 20 rules\n",
    "    if len(rules) >= 20:\n",
    "        break\n",
    "    \n",
    "    # Decrease min_support\n",
    "    min_support -= 0.01\n",
    "\n",
    "print(f\"\\nOptimal min_support found: {min_support:.2f}\")\n",
    "print(f\"Number of rules generated: {len(rules)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f71111",
   "metadata": {},
   "source": [
    "## 10. Generate Association Rules\n",
    "\n",
    "Generate rules with the optimal min_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the rules\n",
    "print(\"Association Rules:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show key columns\n",
    "rules_display = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
    "print(rules_display.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092bce8",
   "metadata": {},
   "source": [
    "## 11. Sort and Visualize Rules\n",
    "\n",
    "Sort rules by lift and confidence (descending), then create scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd76bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort rules by lift and confidence (descending)\n",
    "rules_sorted = rules.sort_values(\n",
    "    by=[\"lift\", \"confidence\"],\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"Top 10 rules sorted by lift and confidence:\")\n",
    "print(\"=\"*80)\n",
    "top_rules = rules_sorted[['antecedents', 'consequents', 'support', 'confidence', 'lift']].head(10)\n",
    "print(top_rules.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3531ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of confidence vs lift\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(rules_sorted[\"confidence\"], rules_sorted[\"lift\"], alpha=0.6, s=100)\n",
    "plt.xlabel(\"Confidence\", fontsize=12)\n",
    "plt.ylabel(\"Lift\", fontsize=12)\n",
    "plt.title(\"Association Rules: Confidence vs Lift\", fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add reference line at lift=1\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='Lift = 1')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualizations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Support vs Confidence\n",
    "axes[0].scatter(rules_sorted[\"support\"], rules_sorted[\"confidence\"], \n",
    "                c=rules_sorted[\"lift\"], cmap='viridis', alpha=0.6, s=100)\n",
    "axes[0].set_xlabel(\"Support\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Confidence\", fontsize=12)\n",
    "axes[0].set_title(\"Support vs Confidence (colored by Lift)\", fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(axes[0].collections[0], ax=axes[0])\n",
    "cbar1.set_label('Lift', fontsize=10)\n",
    "\n",
    "# Plot 2: Support vs Lift\n",
    "axes[1].scatter(rules_sorted[\"support\"], rules_sorted[\"lift\"],\n",
    "                c=rules_sorted[\"confidence\"], cmap='plasma', alpha=0.6, s=100)\n",
    "axes[1].set_xlabel(\"Support\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Lift\", fontsize=12)\n",
    "axes[1].set_title(\"Support vs Lift (colored by Confidence)\", fontsize=12)\n",
    "axes[1].axhline(y=1, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "cbar2 = plt.colorbar(axes[1].collections[0], ax=axes[1])\n",
    "cbar2.set_label('Confidence', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a67c90",
   "metadata": {},
   "source": [
    "### Summary and Interpretation\n",
    "\n",
    "**Association Rules Metrics:**\n",
    "\n",
    "1. **Support:** Frequency of itemset in transactions\n",
    "   - High support = itemset appears frequently\n",
    "   - Low support = rare itemset\n",
    "\n",
    "2. **Confidence:** Probability of consequent given antecedent\n",
    "   - Confidence(A â†’ B) = P(B|A)\n",
    "   - High confidence = strong implication\n",
    "\n",
    "3. **Lift:** Ratio of observed to expected confidence\n",
    "   - Lift > 1: Positive correlation (A and B occur together more than expected)\n",
    "   - Lift = 1: No correlation (independence)\n",
    "   - Lift < 1: Negative correlation (A and B occur together less than expected)\n",
    "\n",
    "**Interpretation of Results:**\n",
    "\n",
    "- Rules with high lift indicate strong associations between items\n",
    "- The scatter plot shows the relationship between confidence and lift\n",
    "- Rules above lift=1 are meaningful (items are purchased together more often than by chance)\n",
    "- High confidence + high lift = actionable rules for recommendations\n",
    "- Support indicates how frequently the rule applies to transactions\n",
    "\n",
    "**Business Applications:**\n",
    "\n",
    "- Product placement: Put associated items near each other\n",
    "- Cross-selling: Recommend consequent items when antecedent is purchased\n",
    "- Bundle offers: Create bundles based on high-lift associations\n",
    "- Inventory management: Stock associated items together"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
